name: 'Collect Logs and Analyze'
description: 'Action to collect logs from a failed workflow run and analyze them using a Python script.'

inputs:
  run_id:
    description: 'The workflow run ID to analyze'
    required: true
  repo_owner:
    description: 'The owner of the repository'
    required: true
  repo_name:
    description: 'The name of the repository'
    required: true
  github_token:
    description: 'GitHub token'
    required: true
  # custom_service_cookie:
  #   description: 'Custom service cookie'
  #   required: true

runs:
  using: 'composite'
  steps:
    - name: Checkout logs_summary_action repository
      uses: actions/checkout@v2
      with:
        repository: shivendratiwari07/logs_summary_action
        path: logs_summary_action

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Install dependencies
      run: |
        python -m venv logs_summary_action/myenv
        source logs_summary_action/myenv/bin/activate
        pip install -r logs_summary_action/requirements.txt
        pip install requests
      shell: bash

    - name: Wait for all jobs to complete or timeout
      id: wait_for_jobs
      run: |
        MAX_ATTEMPTS=180
        SLEEP_TIME=10
        ATTEMPT=0
        all_jobs_completed=false
        while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
          response=$(curl -s -H "Authorization: token ${{ inputs.github_token }}" \
            "https://api.github.com/repos/${{ inputs.repo_owner }}/${{ inputs.repo_name }}/actions/runs/${{ inputs.run_id }}/jobs")
          if [ $? -ne 0 ] || [ -z "$response" ]; then
            echo "Error fetching workflow jobs or empty response. Exiting..."
            exit 1
          fi
          incomplete_jobs=$(echo "$response" | jq -r '.jobs[] | select(.name != "collect-logs" and (.status == "queued" or .status == "in_progress"))')
          if [ -z "$incomplete_jobs" ]; then
            echo "All jobs have completed."
            all_jobs_completed=true
            break
          else
            echo "Waiting for jobs to complete..."
            ATTEMPT=$((ATTEMPT + 1))
            sleep $SLEEP_TIME
          fi
        done
        if [ "$all_jobs_completed" = false ]; then
          echo "Jobs did not complete within the expected time. Proceeding with available job statuses."
        fi
        echo "$response" > jobs_response.json
      shell: bash

    - name: Fetch and analyze job statuses
      id: fetch_job_statuses
      run: |
        response=$(cat jobs_response.json)
        echo "Listing all job statuses:"
        echo "$response" | jq -r '.jobs[]? | "\(.name) - \(.conclusion) - Job ID: \(.id)"'
        echo "$response" | jq -r '.jobs[]? | "\(.name) - \(.conclusion)"' > job_statuses.txt
        grep "failure" job_statuses.txt > failed_jobs.txt || true
        if [ -s failed_jobs.txt ]; then
          echo "Failed jobs detected."
          echo "::set-output name=run_analysis::true"
        else
          echo "No failed jobs detected. Skipping log analysis."
          echo "::set-output name=run_analysis::false"
        fi
      shell: bash

    - name: Run log analysis
      if: ${{ steps.fetch_job_statuses.outputs.run_analysis == 'true' }}
      env:
        CUSTOM_SERVICE_COOKIE: ${{ secrets.CUSTOM_SERVICE_COOKIE }}
      run: |
        export GITHUB_TOKEN="${{ inputs.github_token }}"
        export REPO_OWNER="${{ inputs.repo_owner }}"
        export REPO_NAME="${{ inputs.repo_name }}"
        export CUSTOM_SERVICE_COOKIE="${{ env.CUSTOM_SERVICE_COOKIE }}"
        #export CUSTOM_SERVICE_COOKIE="${{ inputs.custom_service_cookie }}"
        export GITHUB_RUN_ID="${{ inputs.run_id }}"
        source logs_summary_action/myenv/bin/activate
        echo "Current directory:"
        pwd
        echo "Listing the root directory files:"
        ls -la logs_summary_action
        python logs_summary_action/script/debug_fetch_logs.py
      shell: bash

    - name: List files after analysis
      run: |
        echo "Listing the files in the logs_summary_action/scripts directory"
        ls -la logs_summary_action/script/
      shell: bash

    - name: Display analysis summary
      if: always()
      run: |
        echo "Debug: Checking if summary files exist..."
        summary_files=$(ls logs_summary_action/script/*_analysis_*.txt 2>/dev/null || true)
        echo "Found summary files: $summary_files"
        if [ -n "$summary_files" ]; then
          for file in $summary_files; do
            job_name=$(basename "$file" | sed 's/_analysis_.*//')
            echo "### Job Name: $job_name" >> $GITHUB_STEP_SUMMARY
            echo "Appending content of file: $file into summary"
            sed 's/Root Cause Summary:/Root cause of Job failure:/g' "$file" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          done
        else
          echo "### All jobs ran successfully" >> $GITHUB_STEP_SUMMARY
        fi
      shell: bash

    - name: Display summary
      run: |
        echo "Debug: Displaying summary file content..."
        cat $GITHUB_STEP_SUMMARY
      shell: bash

# name: 'Collect Logs and Analyze'
# description: 'Action to collect logs from a failed workflow run and analyze them using a Python script.'

# inputs:
#   run_id:
#     description: 'The workflow run ID to analyze'
#     required: true
#   repo_owner:
#     description: 'The owner of the repository'
#     required: true
#   repo_name:
#     description: 'The name of the repository'
#     required: true
#   github_token:
#     description: 'GitHub token'
#     required: true
#   custom_service_cookie:
#     description: 'Custom service cookie'
#     required: true

# runs:
#   using: 'composite'
#   steps:
#     - name: Checkout repository
#       uses: actions/checkout@v2
#       with:
#         repository: shivendratiwari07/logs_summary_action
#         path: logs_summary_action

#     - name: Set up Python 3.12
#       uses: actions/setup-python@v4
#       with:
#         python-version: '3.12'

#     - name: Install dependencies
#       run: |
#         python -m venv myenv
#         source myenv/bin/activate
#         pip install -r requirements.txt
#         pip install requests
#       shell: bash

#     - name: Wait for all jobs to complete or timeout
#       id: wait_for_jobs
#       run: |
#         MAX_ATTEMPTS=180  # Adjust this to change the total wait time
#         SLEEP_TIME=10    # Time to wait between checks (in seconds)
#         ATTEMPT=0
#         all_jobs_completed=false

#         while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
#           response=$(curl -s -H "Authorization: token ${{ inputs.github_token }}" \
#             "https://api.github.com/repos/${{ inputs.repo_owner }}/${{ inputs.repo_name }}/actions/runs/${{ inputs.run_id }}/jobs")

#           if [ $? -ne 0 ] || [ -z "$response" ]; then
#             echo "Error fetching workflow jobs or empty response. Exiting..."
#             exit 1
#           fi

#           # Filter out the collect-logs job from the list of incomplete jobs
#           incomplete_jobs=$(echo "$response" | jq -r '.jobs[] | select(.name != "collect-logs" and (.status == "queued" or .status == "in_progress"))')

#           if [ -z "$incomplete_jobs" ]; then
#             echo "All jobs have completed."
#             all_jobs_completed=true
#             break
#           else
#             echo "Waiting for jobs to complete..."
#             ATTEMPT=$((ATTEMPT + 1))
#             sleep $SLEEP_TIME
#           fi
#         done

#         if [ "$all_jobs_completed" = false ]; then
#           echo "Jobs did not complete within the expected time. Proceeding with available job statuses."
#         fi

#         # Save the response to use in the next step
#         echo "$response" > jobs_response.json
#       shell: bash

#     - name: Fetch and analyze job statuses
#       id: fetch_job_statuses
#       run: |
#         # Read the previously fetched jobs response
#         response=$(cat jobs_response.json)

#         echo "Listing all job statuses:"
#         echo "$response" | jq -r '.jobs[]? | "\(.name) - \(.conclusion) - Job ID: \(.id)"'

#         # Write job names and statuses to a file for analysis
#         echo "$response" | jq -r '.jobs[]? | "\(.name) - \(.conclusion)"' > job_statuses.txt

#         # Check if any job has failed
#         grep "failure" job_statuses.txt > failed_jobs.txt || true

#         # Set output for log analysis based on whether any failed jobs were found
#         if [ -s failed_jobs.txt ]; then
#           echo "Failed jobs detected."
#           echo "::set-output name=run_analysis::true"
#         else
#           echo "No failed jobs detected. Skipping log analysis."
#           echo "::set-output name=run_analysis::false"
#         fi
#       shell: bash

#     - name: Run log analysis
#       if: ${{ steps.fetch_job_statuses.outputs.run_analysis == 'true' }}
#       run: |
#         export GITHUB_TOKEN="${{ inputs.github_token }}"
#         export REPO_OWNER="${{ inputs.repo_owner }}"
#         export REPO_NAME="${{ inputs.repo_name }}"
#         export CUSTOM_SERVICE_COOKIE="${{ inputs.custom_service_cookie }}"
#         export GITHUB_RUN_ID="${{ inputs.run_id }}"
#         source myenv/bin/activate
#         echo "Current directory:"
#         pwd
#         echo "Listing the root directory files:"
#         ls -la
#         python script/debug_fetch_logs.py
#       shell: bash

#     - name: List files after analysis
#       run: |
#         echo "Listing the files in the scripts directory"
#         ls -la scripts/
#       shell: bash

#     - name: Display analysis summary
#       if: always()
#       run: |
#         echo "Debug: Checking if summary files exist..."
#         summary_files=$(ls ./scripts/*_analysis_*.txt 2>/dev/null || true)
#         echo "Found summary files: $summary_files"
#         if [ -n "$summary_files" ]; then
#           for file in $summary_files; do
#             job_name=$(basename "$file" | sed 's/_analysis_.*//')
#             echo "### Job Name: $job_name" >> $GITHUB_STEP_SUMMARY
#             echo "Appending content of file: $file into summary"
#             sed 's/Root Cause Summary:/Root cause of Job failure:/g' "$file" >> $GITHUB_STEP_SUMMARY
#             echo "" >> $GITHUB_STEP_SUMMARY
#           done
#         else
#           echo "### All jobs ran successfully" >> $GITHUB_STEP_SUMMARY
#         fi
#       shell: bash

#     - name: Display summary
#       run: |
#         echo "Debug: Displaying summary file content..."
#         cat $GITHUB_STEP_SUMMARY
#       shell: bash




    # - name: List files after analysis
    #     run: ls -la scripts/

    # - name: Display analysis summary
    #     if: always()
    #     run: |
    #       summary_files=$(ls ./scripts/*_analysis_*.txt 2>/dev/null || true)
    #       if [ -n "$summary_files" ]; then
    #         for file in $summary_files; do
    #           job_name=$(basename "$file" | sed 's/_analysis_.*//')
    #           echo "### Job Name: $job_name" >> $GITHUB_STEP_SUMMARY
    #           # Replace 'Summary of root cause:' with 'Root cause of Job failure:'
    #           sed 's/Root Cause Summary:/Root cause of Job failure:/g' "$file" >> $GITHUB_STEP_SUMMARY
    #           echo "" >> $GITHUB_STEP_SUMMARY  # Add a blank line for readability
    #         done
    #       else
    #         echo "### All jobs ran successfully" >> $GITHUB_STEP_SUMMARY
    #       fi

    # - name: Display summary
    #     run: cat $GITHUB_STEP_SUMMARY














# name: 'Collect Logs and Analyze'
# description: 'Action to collect logs from a failed workflow run and analyze them using a Python script.'
# inputs:
#   run_id:
#     description: 'The workflow run ID to analyze'
#     required: true
#   repo_owner:
#     description: 'The owner of the repository'
#     required: true
#   repo_name:
#     description: 'The name of the repository'
#     required: true
#   github_token:
#     description: 'GitHub token'
#     required: true
#   custom_service_cookie:
#     description: 'Custom service cookie'
#     required: true

# runs:
#   using: 'composite'
#   steps:
#     - name: Checkout repository
#       uses: actions/checkout@v2

#     - name: Set up Python 3.12
#       uses: actions/setup-python@v4
#       with:
#         python-version: '3.12'

#     - name: Install dependencies
#       run: |
#         python -m venv myenv
#         source myenv/bin/activate
#         pip install -r requirements.txt
#         pip install requests
#       shell: bash

#     - name: Run log analysis
#       run: |
#         export GITHUB_TOKEN="${{ inputs.github_token }}"
#         export REPO_OWNER="${{ inputs.repo_owner }}"
#         export REPO_NAME="${{ inputs.repo_name }}"
#         export CUSTOM_SERVICE_COOKIE="${{ inputs.custom_service_cookie }}"
#         export GITHUB_RUN_ID="${{ inputs.run_id }}"
#         source myenv/bin/activate
#         python scripts/debug_fetch_logs.py
#       shell: bash
